{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy import signal\n",
    "from scipy import linalg as la\n",
    "from scipy import special as ss\n",
    "from utils import unroll\n",
    "from utils.op import transition\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "import pickle\n",
    "import pdb\n",
    "from einops import rearrange, repeat\n",
    "import opt_einsum as oe\n",
    "\n",
    "contract = oe.contract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'TRAIN_WINDOW_SIZE':90, # 90일치로 학습\n",
    "    'PREDICT_SIZE':21, # 21일치 예측\n",
    "    'EPOCHS':20,\n",
    "    'LEARNING_RATE':1e-4,\n",
    "    'BATCH_SIZE':4096,\n",
    "    'SEED':41\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./train.csv').drop(columns=['ID', '제품'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15890/15890 [02:07<00:00, 124.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# Data Scaling\n",
    "scale_max_dict = {}\n",
    "scale_min_dict = {}\n",
    "\n",
    "for idx in tqdm(range(len(train_data))):\n",
    "    maxi = np.max(train_data.iloc[idx,4:])\n",
    "    mini = np.min(train_data.iloc[idx,4:])\n",
    "    \n",
    "    if maxi == mini :\n",
    "        train_data.iloc[idx,4:] = 0\n",
    "    else:\n",
    "        train_data.iloc[idx,4:] = (train_data.iloc[idx,4:] - mini) / (maxi - mini)\n",
    "    \n",
    "    scale_max_dict[idx] = maxi\n",
    "    scale_min_dict[idx] = mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_columns = ['대분류', '중분류', '소분류', '브랜드']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    label_encoder.fit(train_data[col])\n",
    "    train_data[col] = label_encoder.transform(train_data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_data(data, train_size=CFG['TRAIN_WINDOW_SIZE'], predict_size=CFG['PREDICT_SIZE']):\n",
    "    '''\n",
    "    학습 기간 블럭, 예측 기간 블럭의 세트로 데이터를 생성\n",
    "    data : 일별 판매량\n",
    "    train_size : 학습에 활용할 기간\n",
    "    predict_size : 추론할 기간\n",
    "    '''\n",
    "    num_rows = len(data)\n",
    "    window_size = train_size + predict_size\n",
    "    \n",
    "    input_data = np.empty((num_rows * (len(data.columns) - window_size + 1), train_size, len(data.iloc[0, :4]) + 1))\n",
    "    target_data = np.empty((num_rows * (len(data.columns) - window_size + 1), predict_size))\n",
    "    \n",
    "    for i in tqdm(range(num_rows)):\n",
    "        encode_info = np.array(data.iloc[i, :4])\n",
    "        sales_data = np.array(data.iloc[i, 4:])\n",
    "        \n",
    "        for j in range(len(sales_data) - window_size + 1):\n",
    "            window = sales_data[j : j + window_size]\n",
    "            temp_data = np.column_stack((np.tile(encode_info, (train_size, 1)), window[:train_size]))\n",
    "            input_data[i * (len(data.columns) - window_size + 1) + j] = temp_data\n",
    "            target_data[i * (len(data.columns) - window_size + 1) + j] = window[train_size:]\n",
    "    \n",
    "    return input_data, target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predict_data(data, train_size=CFG['TRAIN_WINDOW_SIZE']):\n",
    "    '''\n",
    "    평가 데이터(Test Dataset)를 추론하기 위한 Input 데이터를 생성\n",
    "    data : 일별 판매량\n",
    "    train_size : 추론을 위해 필요한 일별 판매량 기간 (= 학습에 활용할 기간)\n",
    "    '''\n",
    "    num_rows = len(data)\n",
    "    \n",
    "    input_data = np.empty((num_rows, train_size, len(data.iloc[0, :4]) + 1))\n",
    "    \n",
    "    for i in tqdm(range(num_rows)):\n",
    "        encode_info = np.array(data.iloc[i, :4])\n",
    "        sales_data = np.array(data.iloc[i, -train_size:])\n",
    "        \n",
    "        window = sales_data[-train_size : ]\n",
    "        temp_data = np.column_stack((np.tile(encode_info, (train_size, 1)), window[:train_size]))\n",
    "        input_data[i] = temp_data\n",
    "    \n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15890/15890 [00:51<00:00, 306.06it/s]\n",
      "100%|██████████| 15890/15890 [00:10<00:00, 1549.64it/s]\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target = make_train_data(train_data)\n",
    "test_input = make_predict_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4487336, 90, 5),\n",
       " (4487336, 21),\n",
       " (1121834, 90, 5),\n",
       " (1121834, 21),\n",
       " (15890, 90, 5))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train / Validation Split\n",
    "data_len = len(train_input)\n",
    "val_input = train_input[-int(data_len*0.2):]\n",
    "val_target = train_target[-int(data_len*0.2):]\n",
    "train_input = train_input[:-int(data_len*0.2)]\n",
    "train_target = train_target[:-int(data_len*0.2)]\n",
    "\n",
    "train_input.shape, train_target.shape, val_input.shape, val_target.shape, test_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.Y is not None:\n",
    "            return torch.Tensor(self.X[index]), torch.Tensor(self.Y[index])\n",
    "        return torch.Tensor(self.X[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_input, train_target)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "\n",
    "val_dataset = CustomDataset(val_input, val_target)\n",
    "val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.utils.data as data_utils\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiPPO_LegT(nn.Module):\n",
    "    def __init__(self, N, dt=1.0, discretization='bilinear'):\n",
    "        \"\"\"\n",
    "        N: the order of the HiPPO projection\n",
    "        dt: discretization step size - should be roughly inverse to the length of the sequence\n",
    "        \"\"\"\n",
    "        super(HiPPO_LegT,self).__init__()\n",
    "        self.N = N\n",
    "        A, B = transition('lmu', N)\n",
    "        C = np.ones((1, N))\n",
    "        D = np.zeros((1,))\n",
    "        # dt, discretization options\n",
    "        A, B, _, _, _ = signal.cont2discrete((A, B, C, D), dt=dt, method=discretization)\n",
    "\n",
    "        B = B.squeeze(-1)\n",
    "\n",
    "        self.register_buffer('A', torch.Tensor(A).to(device)) \n",
    "        self.register_buffer('B', torch.Tensor(B).to(device)) \n",
    "        vals = np.arange(0.0, 1.0, dt)\n",
    "        self.register_buffer('eval_matrix',  torch.Tensor(\n",
    "            ss.eval_legendre(np.arange(N)[:, None], 1 - 2 * vals).T).to(device))\n",
    "    def forward(self, inputs):  # torch.Size([128, 1, 1]) -\n",
    "        \"\"\"\n",
    "        inputs : (length, ...)\n",
    "        output : (length, ..., N) where N is the order of the HiPPO projection\n",
    "        \"\"\"\n",
    "\n",
    "        c = torch.zeros(inputs.shape[:-1] + tuple([self.N])).to(device)  # torch.Size([1, 256])\n",
    "        cs = []\n",
    "        for f in inputs.permute([-1, 0, 1]):\n",
    "            f = f.unsqueeze(-1)\n",
    "            # f: [1,1]\n",
    "            new = f @ self.B.unsqueeze(0) # [B, D, H, 256]\n",
    "            c = F.linear(c, self.A) + new\n",
    "            # c = [1,256] * [256,256] + [1, 256]\n",
    "            cs.append(c)\n",
    "        return torch.stack(cs, dim=0)\n",
    "\n",
    "    def reconstruct(self, c):\n",
    "        a = (self.eval_matrix @ c.unsqueeze(-1)).squeeze(-1)\n",
    "        return (self.eval_matrix @ c.unsqueeze(-1)).squeeze(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,seq_len, modes1,compression=0,ratio=0.5,mode_type=2):\n",
    "        super(SpectralConv1d, self).__init__()\n",
    "            \n",
    "\n",
    "        \"\"\"\n",
    "        1D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n",
    "        \"\"\"\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1  #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
    "        self.compression = compression\n",
    "        self.ratio = ratio \n",
    "        self.mode_type=mode_type\n",
    "        if self.mode_type ==1:\n",
    "            #modes2=modes1-10000\n",
    "            modes2 = modes1\n",
    "            self.modes2 =min(modes2,seq_len//2)\n",
    "            self.index0 = list(range(0, int(ratio*min(seq_len//2, modes2))))\n",
    "            self.index1 = list(range(len(self.index0),self.modes2))\n",
    "            np.random.shuffle(self.index1)\n",
    "            self.index1 = self.index1[:min(seq_len//2,self.modes2)-int(ratio*min(seq_len//2, modes2))]\n",
    "            self.index = self.index0+self.index1\n",
    "            self.index.sort()\n",
    "        elif self.mode_type > 1:\n",
    "            #modes2=modes1-1000\n",
    "            modes2 = modes1\n",
    "            self.modes2 =min(modes2,seq_len//2)\n",
    "            self.index = list(range(0, seq_len//2))\n",
    "            np.random.shuffle(self.index)\n",
    "            self.index = self.index[:self.modes2]\n",
    "        else:\n",
    "            self.modes2 =min(modes1,seq_len//2)\n",
    "            self.index = list(range(0, self.modes2))\n",
    "\n",
    "        self.scale = (1 / (in_channels*out_channels))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, len(self.index), dtype=torch.cfloat))\n",
    "        if self.compression > 0:\n",
    "            print('compressed version')\n",
    "            self.weights0 = nn.Parameter(self.scale * torch.rand(in_channels,self.compression,dtype=torch.cfloat))\n",
    "            self.weights1 = nn.Parameter(self.scale * torch.rand(self.compression,self.compression, len(self.index), dtype=torch.cfloat))\n",
    "            self.weights2 = nn.Parameter(self.scale * torch.rand(self.compression,out_channels, dtype=torch.cfloat))\n",
    "        #print(self.modes2)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        B, H,E, N = x.shape\n",
    "        # Compute Fourier coeffcients up to factor of e^(- something constant)\n",
    "        x_ft = torch.fft.rfft(x)\n",
    "        #pdb.set_trace()\n",
    "        # Multiply relevant Fourier modes\n",
    "        out_ft = torch.zeros(B,H, self.out_channels, x.size(-1)//2 + 1,  device=x.device, dtype=torch.cfloat)\n",
    "        #a = x_ft[:, :,:, :self.modes1]\n",
    "        #out_ft[:, :,:, :self.modes1] = torch.einsum(\"bjix,iox->bjox\", a, self.weights1)\n",
    "        if self.compression ==0:\n",
    "            if self.modes1>1000:\n",
    "                for wi, i in enumerate(self.index):\n",
    "                    #print(self.index)\n",
    "                    #print(out_ft.shape)\n",
    "                    out_ft[:, :, :, i] = torch.einsum('bji,io->bjo',(x_ft[:, :, :, i], self.weights1[:, :,wi]))\n",
    "            else:\n",
    "                a = x_ft[:, :,:, :self.modes2]\n",
    "                out_ft[:, :,:, :self.modes2] = torch.einsum(\"bjix,iox->bjox\", a, self.weights1)\n",
    "        elif self.compression > 0:\n",
    "            a = x_ft[:, :,:, :self.modes2]\n",
    "            a = torch.einsum(\"bjix,ih->bjhx\", a, self.weights0)\n",
    "            a = torch.einsum(\"bjhx,hkx->bjkx\", a, self.weights1)\n",
    "            out_ft[:, :,:, :self.modes2] = torch.einsum(\"bjkx,ko->bjox\", a, self.weights2)\n",
    "        # Return to physical space\n",
    "        x = torch.fft.irfft(out_ft, n=x.size(-1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,seq_len, modes1,compression=0,ratio=0.5,mode_type=0):\n",
    "        super(SpectralConv1d, self).__init__()\n",
    "            \n",
    "\n",
    "        \"\"\"\n",
    "        1D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n",
    "        \"\"\"\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1  #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
    "        self.compression = compression\n",
    "        self.ratio = ratio \n",
    "        self.mode_type=mode_type\n",
    "        if self.mode_type ==1:\n",
    "            #modes2=modes1-10000\n",
    "            modes2 = modes1\n",
    "            self.modes2 =min(modes2,seq_len//2)\n",
    "            self.index0 = list(range(0, int(ratio*min(seq_len//2, modes2))))\n",
    "            self.index1 = list(range(len(self.index0),self.modes2))\n",
    "            np.random.shuffle(self.index1)\n",
    "            self.index1 = self.index1[:min(seq_len//2,self.modes2)-int(ratio*min(seq_len//2, modes2))]\n",
    "            self.index = self.index0+self.index1\n",
    "            self.index.sort()\n",
    "        elif self.mode_type > 1:\n",
    "            #modes2=modes1-1000\n",
    "            modes2 = modes1\n",
    "            self.modes2 =min(modes2,seq_len//2)\n",
    "            self.index = list(range(0, seq_len//2))\n",
    "            np.random.shuffle(self.index)\n",
    "            self.index = self.index[:self.modes2]\n",
    "        else:\n",
    "            self.modes2 =min(modes1,seq_len//2)\n",
    "            self.index = list(range(0, self.modes2))\n",
    "\n",
    "        self.scale = (1 / (in_channels*out_channels))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, len(self.index), dtype=torch.cfloat))\n",
    "        if self.compression > 0:\n",
    "            print('compressed version')\n",
    "            self.weights0 = nn.Parameter(self.scale * torch.rand(in_channels,self.compression,dtype=torch.cfloat))\n",
    "            self.weights1 = nn.Parameter(self.scale * torch.rand(self.compression,self.compression, len(self.index), dtype=torch.cfloat))\n",
    "            self.weights2 = nn.Parameter(self.scale * torch.rand(self.compression,out_channels, dtype=torch.cfloat))\n",
    "        #print(self.modes2)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        B, H,E, N = x.shape\n",
    "        # Compute Fourier coeffcients up to factor of e^(- something constant)\n",
    "        x_ft = torch.fft.rfft(x)\n",
    "        #pdb.set_trace()\n",
    "        # Multiply relevant Fourier modes\n",
    "        out_ft = torch.zeros(B,H, self.out_channels, x.size(-1)//2 + 1,  device=x.device, dtype=torch.cfloat)\n",
    "        #a = x_ft[:, :,:, :self.modes1]\n",
    "        #out_ft[:, :,:, :self.modes1] = torch.einsum(\"bjix,iox->bjox\", a, self.weights1)\n",
    "        if self.compression ==0:\n",
    "            if self.modes1>1000:\n",
    "                for wi, i in enumerate(self.index):\n",
    "                    #print(self.index)\n",
    "                    #print(out_ft.shape)\n",
    "                    out_ft[:, :, :, i] = torch.einsum('bji,io->bjo',(x_ft[:, :, :, i], self.weights1[:, :,wi]))\n",
    "            else:\n",
    "                a = x_ft[:, :,:, :self.modes2]\n",
    "                out_ft[:, :,:, :self.modes2] = torch.einsum(\"bjix,iox->bjox\", a, self.weights1)\n",
    "        elif self.compression > 0:\n",
    "            a = x_ft[:, :,:, :self.modes2]\n",
    "            a = torch.einsum(\"bjix,ih->bjhx\", a, self.weights0)\n",
    "            a = torch.einsum(\"bjhx,hkx->bjkx\", a, self.weights1)\n",
    "            out_ft[:, :,:, :self.modes2] = torch.einsum(\"bjkx,ko->bjox\", a, self.weights2)\n",
    "        # Return to physical space\n",
    "        x = torch.fft.irfft(out_ft, n=x.size(-1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compressed version\n",
      "compressed version\n",
      "compressed version\n",
      "model size 0.029300689697265625\n",
      "input shape torch.Size([32, 336, 7])\n",
      "output shape torch.Size([32, 720, 7])\n",
      "input shape torch.Size([32, 336, 7])\n",
      "hippo shape torch.Size([32, 7, 256, 336])\n",
      "processed hippo shape torch.Size([32, 7, 256, 336])\n",
      "output shape torch.Size([32, 720, 7])\n"
     ]
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoformer is the first method to achieve the series-wise connection,\n",
    "    with inherent O(LlogL) complexity\n",
    "    \"\"\"\n",
    "    def __init__(self, configs, N=512, N2=32):\n",
    "        super(Model, self).__init__()\n",
    "        self.configs = configs\n",
    "        # self.modes = configs.modes\n",
    "        self.seq_len = configs.seq_len\n",
    "        self.label_len = configs.label_len\n",
    "        self.pred_len = configs.pred_len\n",
    "        \n",
    "        self.seq_len_all = self.seq_len+self.label_len\n",
    "        \n",
    "        self.output_attention = configs.output_attention\n",
    "        self.layers = configs.e_layers\n",
    "        self.modes1 = min(configs.modes1,self.pred_len//2)\n",
    "        #self.modes1 = 32\n",
    "        self.enc_in = configs.enc_in\n",
    "        self.proj=False\n",
    "        self.e_layers = configs.e_layers\n",
    "        self.mode_type=configs.mode_type\n",
    "        if self.configs.ours:\n",
    "            #b, s, f means b, f\n",
    "            self.affine_weight = nn.Parameter(torch.ones(1, 1, configs.enc_in))\n",
    "            self.affine_bias = nn.Parameter(torch.zeros(1, 1, configs.enc_in))\n",
    "            \n",
    "        if configs.enc_in>1000:\n",
    "            self.proj=True\n",
    "            self.conv1 = nn.Conv1d(configs.enc_in,configs.d_model,1)\n",
    "            self.conv2 = nn.Conv1d(configs.d_model,configs.dec_in,1)\n",
    "            self.d_model = configs.d_model\n",
    "            self.affine_weight = nn.Parameter(torch.ones(1, 1, configs.d_model))\n",
    "            self.affine_bias = nn.Parameter(torch.zeros(1, 1, configs.d_model))\n",
    "        if self.configs.ab == 2:\n",
    "            self.multiscale = [1,2,4]\n",
    "            #self.multiscale = [1]\n",
    "            self.window_size=[256]\n",
    "            self.legts = nn.ModuleList([HiPPO_LegT(N=n, dt=1./self.pred_len/i) for n in self.window_size for i in self.multiscale])\n",
    "            self.spec_conv_1 = nn.ModuleList([SpectralConv1d(in_channels=n, out_channels=n,seq_len=min(self.pred_len,self.seq_len), modes1=configs.modes1,compression=configs.version,ratio=configs.ratio,mode_type=self.mode_type) for n in self.window_size for _ in range(len(self.multiscale))])               \n",
    "            self.mlp = nn.Linear(len(self.multiscale)*len(self.window_size), 1)\n",
    "        \n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec_true, x_mark_dec,\n",
    "                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n",
    "        # decomp init\n",
    "        \n",
    "        if self.configs.ab == 2:\n",
    "            return_data=[x_enc]\n",
    "            if self.proj:\n",
    "                x_enc = self.conv1(x_enc.transpose(1,2))\n",
    "                x_enc = x_enc.transpose(1,2)\n",
    "            if self.configs.ours:\n",
    "                means = x_enc.mean(1, keepdim=True).detach()\n",
    "                #mean\n",
    "                x_enc = x_enc - means\n",
    "                #var\n",
    "                stdev = torch.sqrt(torch.var(x_enc, dim=1, keepdim=True, unbiased=False)+ 1e-5).detach() \n",
    "                x_enc /= stdev\n",
    "                # affine\n",
    "                x_enc = x_enc * self.affine_weight + self.affine_bias\n",
    "            B, L, E = x_enc.shape\n",
    "            seq_len = self.seq_len\n",
    "            x_decs = []\n",
    "            jump_dist=0\n",
    "            for i in range(0, len(self.multiscale)*len(self.window_size)):\n",
    "                x_in_len = self.multiscale[i%len(self.multiscale)] * self.pred_len\n",
    "                x_in = x_enc[:, -x_in_len:]\n",
    "                legt = self.legts[i]\n",
    "                x_in_c = legt(x_in.transpose(1, 2)).permute([1, 2,3, 0])[:,:,:,jump_dist:]\n",
    "                out1 = self.spec_conv_1[i](x_in_c)\n",
    "                if self.seq_len >= self.pred_len:\n",
    "                    x_dec_c = out1.transpose(2, 3)[:,:, self.pred_len-1-jump_dist, :]\n",
    "                else:\n",
    "                    x_dec_c = out1.transpose(2, 3)[:,:, -1, :]\n",
    "                x_dec = x_dec_c @ (legt.eval_matrix[-self.pred_len:,:].T)\n",
    "                x_decs += [x_dec]\n",
    "            return_data.append(x_in_c)\n",
    "            return_data.append(out1)\n",
    "            x_dec = self.mlp(torch.stack(x_decs, dim=-1)).squeeze(-1).permute(0,2,1)\n",
    "            if self.configs.ours:\n",
    "                x_dec = x_dec - self.affine_bias\n",
    "                x_dec = x_dec / (self.affine_weight + 1e-10)\n",
    "                x_dec = x_dec * stdev\n",
    "                x_dec = x_dec + means\n",
    "            if self.proj:\n",
    "                x_dec = self.conv2(x_dec.transpose(1,2))\n",
    "                x_dec = x_dec.transpose(1,2)\n",
    "            return_data.append(x_dec)\n",
    "        if self.output_attention:\n",
    "            return x_dec, return_data\n",
    "        else:\n",
    "            return x_dec,None  # [B, L, D]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    class Configs(object):\n",
    "        ab = 2\n",
    "        modes1 = 8\n",
    "        seq_len = 336\n",
    "        label_len = 0\n",
    "        pred_len = 720\n",
    "        output_attention = True\n",
    "        enc_in = 5\n",
    "        dec_in = 5\n",
    "        d_model = 16\n",
    "        embed = 'timeF'\n",
    "        dropout = 0.05\n",
    "        freq = 'h'\n",
    "        factor = 1\n",
    "        n_heads = 8\n",
    "        d_ff = 16\n",
    "        e_layers = 2\n",
    "        d_layers = 1\n",
    "        moving_avg = 25\n",
    "        c_out = 1\n",
    "        activation = 'gelu'\n",
    "        wavelet = 0\n",
    "        ours = False\n",
    "        version = 16\n",
    "        ratio = 1\n",
    "        mode_type = 0\n",
    "        \n",
    "\n",
    "    configs = Configs()\n",
    "    model = Model(configs).to(device)\n",
    "    optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "\n",
    "    enc = torch.randn([32, configs.seq_len, configs.enc_in]).cuda()\n",
    "    enc_mark = torch.randn([32, configs.seq_len, 4]).cuda()\n",
    "\n",
    "    dec = torch.randn([32, configs.label_len+configs.pred_len, configs.dec_in]).cuda()\n",
    "    dec_mark = torch.randn([32, configs.label_len+configs.pred_len, 4]).cuda()\n",
    "    out=model.forward(enc, enc_mark, dec, dec_mark)\n",
    "    def count_parameters(model):\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print('model size',count_parameters(model)/(1024*1024))\n",
    "    print('input shape',enc.shape)\n",
    "    print('output shape',out[0].shape)\n",
    "    a,b,c,d = out[1]\n",
    "    print('input shape',a.shape)\n",
    "    print('hippo shape',b.shape)\n",
    "    print('processed hippo shape',c.shape)\n",
    "    print('output shape',d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(model, optimizer, train_loader, val_loader, device):\n",
    "#     model.to(device)\n",
    "#     criterion = nn.MSELoss().to(device)\n",
    "#     best_loss = 9999999\n",
    "#     best_model = None\n",
    "    \n",
    "#     for epoch in range(1, CFG['EPOCHS']+1):\n",
    "#         model.train()\n",
    "#         train_loss = []\n",
    "        \n",
    "#         for X, Y in tqdm(iter(train_loader)):\n",
    "#             X = X.to(device)\n",
    "#             Y = Y.to(device)\n",
    "            \n",
    "#             optimizer.zero_grad()\n",
    "            \n",
    "#             output = model(X)\n",
    "#             # print(\"Model Output Shape:\", output.shape)\n",
    "#             # print(\"Target Shape:\", Y.shape)\n",
    "#             loss = criterion(output, Y)\n",
    "            \n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             train_loss.append(loss.item())\n",
    "        \n",
    "#         val_loss = validation(model, val_loader, criterion, device)\n",
    "#         print(f'Epoch : [{epoch}] Train Loss : [{np.mean(train_loss):.5f}] Val Loss : [{val_loss:.5f}]')\n",
    "        \n",
    "#         if best_loss > val_loss:\n",
    "#             best_loss = val_loss\n",
    "#             best_model = model\n",
    "#             print('Model Saved')\n",
    "    \n",
    "#     return best_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def validation(model, val_loader, criterion, device):\n",
    "#     model.eval()\n",
    "#     val_loss = []\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for X, Y in tqdm(iter(val_loader)):\n",
    "#             X = X.to(device)\n",
    "#             Y = Y.to(device)\n",
    "            \n",
    "#             output = model(X)\n",
    "#             loss = criterion(output, Y)\n",
    "            \n",
    "#             val_loss.append(loss.item())\n",
    "#     return np.mean(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "from exp.exp_main import Exp_Main\n",
    "import random\n",
    "import numpy as np\n",
    "#torch.autograd.set_detect_anomaly(True) \n",
    "fix_seed = 2021\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Autoformer & Transformer family for Time Series Forecasting')\n",
    "\n",
    "# basic config\n",
    "parser.add_argument('--is_training', type=int, default=1, help='status')\n",
    "parser.add_argument('--model_id', type=str, default='test', help='model id')\n",
    "parser.add_argument('--model', type=str, default='Reformer',\n",
    "                    help='model name, options: [Autoformer, Informer, Transformer]')\n",
    "\n",
    "# data loader\n",
    "parser.add_argument('--data', type=str, default='ETTh1', help='dataset type')\n",
    "parser.add_argument('--root_path', type=str, default='./data/ETT/', help='root path of the data file')\n",
    "parser.add_argument('--data_path', type=str, default='ETTh1.csv', help='data file')\n",
    "parser.add_argument('--features', type=str, default='M',\n",
    "                    help='forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate')\n",
    "parser.add_argument('--target', type=str, default='OT', help='target feature in S or MS task')\n",
    "parser.add_argument('--freq', type=str, default='h',\n",
    "                    help='freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h')\n",
    "parser.add_argument('--checkpoints', type=str, default='./checkpoints/', help='location of model checkpoints')\n",
    "\n",
    "# forecasting task\n",
    "n = 2400\n",
    "parser.add_argument('--seq_len', type=int, default=n, help='input sequence length')\n",
    "parser.add_argument('--label_len', type=int, default=int(n/2), help='start token length')\n",
    "parser.add_argument('--pred_len', type=int, default=n, help='prediction sequence length')\n",
    "parser.add_argument('--modes1', type=int, default=64, help='modes to be 64')\n",
    "parser.add_argument('--L', type=int, default=3, help='ignore level')\n",
    "parser.add_argument('--base',type=str,default='legendre',help='mwt base')\n",
    "parser.add_argument('--cross_activation',type=str,default='tanh',help='mwt cross atention activation function tanh or softmax')\n",
    "\n",
    "#parser.add_argument('--base',type=str,default='chebyshev',help='mwt base')\n",
    "# model define\n",
    "parser.add_argument('--ab', type=int, default=0, help='ablation version')\n",
    "parser.add_argument('--wavelet', type=int, default=0, help='use wavelet')\n",
    "parser.add_argument('--enc_in', type=int, default=7, help='encoder input size')\n",
    "parser.add_argument('--dec_in', type=int, default=7, help='decoder input size')\n",
    "parser.add_argument('--c_out', type=int, default=7, help='output size')\n",
    "parser.add_argument('--d_model', type=int, default=512, help='dimension of model')\n",
    "parser.add_argument('--n_heads', type=int, default=8, help='num of heads')\n",
    "parser.add_argument('--e_layers', type=int, default=2, help='num of encoder layers')\n",
    "parser.add_argument('--d_layers', type=int, default=1, help='num of decoder layers')\n",
    "parser.add_argument('--d_ff', type=int, default=2048, help='dimension of fcn')\n",
    "parser.add_argument('--moving_avg',default=[24], help='window size of moving average')\n",
    "#parser.add_argument('--moving_avg', type=int,action='append', help='window size of moving average')\n",
    "parser.add_argument('--factor', type=int, default=1, help='attn factor')\n",
    "parser.add_argument('--distil', action='store_false',\n",
    "                    help='whether to use distilling in encoder, using this argument means not using distilling',\n",
    "                    default=True)\n",
    "parser.add_argument('--dropout', type=float, default=0.05, help='dropout')\n",
    "parser.add_argument('--embed', type=str, default='timeF',\n",
    "                    help='time features encoding, options:[timeF, fixed, learned]')\n",
    "parser.add_argument('--activation', type=str, default='gelu', help='activation')\n",
    "parser.add_argument('--output_attention', action='store_true', help='whether to output attention in ecoder')\n",
    "parser.add_argument('--do_predict', action='store_true', help='whether to predict unseen future data')\n",
    "\n",
    "# optimization\n",
    "parser.add_argument('--num_workers', type=int, default=10, help='data loader num workers')\n",
    "parser.add_argument('--itr', type=int, default=2, help='experiments times')\n",
    "parser.add_argument('--train_epochs', type=int, default=10, help='train epochs')\n",
    "parser.add_argument('--batch_size', type=int, default=32, help='batch size of train input data')\n",
    "parser.add_argument('--patience', type=int, default=3, help='early stopping patience')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.0001, help='optimizer learning rate')\n",
    "parser.add_argument('--des', type=str, default='test', help='exp description')\n",
    "parser.add_argument('--loss', type=str, default='mse', help='loss function')\n",
    "parser.add_argument('--lradj', type=str, default='type1', help='adjust learning rate')\n",
    "parser.add_argument('--use_amp', action='store_true', help='use automatic mixed precision training', default=False)\n",
    "\n",
    "# GPU\n",
    "parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='gpu')\n",
    "parser.add_argument('--use_multi_gpu', action='store_true', help='use multiple gpus', default=False)\n",
    "parser.add_argument('--devices', type=str, default='0,1', help='device ids of multile gpus')\n",
    "parser.add_argument('--add_noise_vali',type=bool,default=False,help='add noise in vali')\n",
    "parser.add_argument('--add_noise_train',type=bool,default=False,help='add noise in training')\n",
    "parser.add_argument('--ours', default=False, action='store_true')\n",
    "parser.add_argument('--version', type=int, default=0, help='compression')\n",
    "parser.add_argument('--seasonal',type=int,default=7)\n",
    "parser.add_argument('--mode_type',type=int,default=0)\n",
    "parser.add_argument('--ratio', type=float, default=0.5, help='dropout')\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "\n",
    "if args.use_gpu and args.use_multi_gpu:\n",
    "    args.dvices = args.devices.replace(' ', '')\n",
    "    device_ids = args.devices.split(',')\n",
    "    args.device_ids = [int(id_) for id_ in device_ids]\n",
    "    args.gpu = args.device_ids[0]\n",
    "\n",
    "print('Args in experiment:')\n",
    "print(args)\n",
    "\n",
    "Exp = Exp_Main\n",
    "\n",
    "if args.is_training:\n",
    "    for ii in range(args.itr):\n",
    "        # setting record of experiments\n",
    "        setting = '{}_{}_fourCroguidedm2TanhR_ab{}_modes{}_uwl{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
    "            args.model_id,\n",
    "            args.model,\n",
    "            args.ab,\n",
    "            args.modes1,\n",
    "            args.wavelet,\n",
    "            args.data,\n",
    "            args.features,\n",
    "            args.seq_len,\n",
    "            args.label_len,\n",
    "            args.pred_len,\n",
    "            args.d_model,\n",
    "            args.n_heads,\n",
    "            args.e_layers,\n",
    "            args.d_layers,\n",
    "            args.d_ff,\n",
    "            args.factor,\n",
    "            args.embed,\n",
    "            args.distil,\n",
    "            args.des, ii)\n",
    "\n",
    "        exp = Exp(args)  # set experiments\n",
    "        print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "        exp.train(setting)\n",
    "\n",
    "        print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "        exp.test(setting)\n",
    "\n",
    "        if args.do_predict:\n",
    "            print('>>>>>>>predicting : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "            exp.predict(setting, True)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "else:\n",
    "    ii = 0\n",
    "    setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(args.model_id,\n",
    "                                                                                                  args.model,\n",
    "                                                                                                  args.data,\n",
    "                                                                                                  args.features,\n",
    "                                                                                                  args.seq_len,\n",
    "                                                                                                  args.label_len,\n",
    "                                                                                                  args.pred_len,\n",
    "                                                                                                  args.d_model,\n",
    "                                                                                                  args.n_heads,\n",
    "                                                                                                  args.e_layers,\n",
    "                                                                                                  args.d_layers,\n",
    "                                                                                                  args.d_ff,\n",
    "                                                                                                  args.factor,\n",
    "                                                                                                  args.embed,\n",
    "                                                                                                  args.distil,\n",
    "                                                                                                  args.des, ii)\n",
    "\n",
    "    exp = Exp(args)  # set experiments\n",
    "    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "    exp.test(setting, test=1)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 38.70it/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = CustomDataset(test_input, None)\n",
    "test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "\n",
    "def inference(model, test_loader, device):\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X in tqdm(iter(test_loader)):\n",
    "            X = X.to(device)\n",
    "            \n",
    "            output = model(X)\n",
    "            \n",
    "            # 모델 출력인 output을 CPU로 이동하고 numpy 배열로 변환\n",
    "            output = output.cpu().numpy()\n",
    "            \n",
    "            predictions.extend(output)\n",
    "    \n",
    "    return np.array(predictions)\n",
    "\n",
    "pred = inference(infer_model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론 결과를 inverse scaling\n",
    "for idx in range(len(pred)):\n",
    "    pred[idx, :] = pred[idx, :] * (scale_max_dict[idx] - scale_min_dict[idx]) + scale_min_dict[idx]\n",
    "    \n",
    "# 결과 후처리\n",
    "pred = np.round(pred, 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15890, 21)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>2023-04-05</th>\n",
       "      <th>2023-04-06</th>\n",
       "      <th>2023-04-07</th>\n",
       "      <th>2023-04-08</th>\n",
       "      <th>2023-04-09</th>\n",
       "      <th>2023-04-10</th>\n",
       "      <th>2023-04-11</th>\n",
       "      <th>2023-04-12</th>\n",
       "      <th>2023-04-13</th>\n",
       "      <th>...</th>\n",
       "      <th>2023-04-16</th>\n",
       "      <th>2023-04-17</th>\n",
       "      <th>2023-04-18</th>\n",
       "      <th>2023-04-19</th>\n",
       "      <th>2023-04-20</th>\n",
       "      <th>2023-04-21</th>\n",
       "      <th>2023-04-22</th>\n",
       "      <th>2023-04-23</th>\n",
       "      <th>2023-04-24</th>\n",
       "      <th>2023-04-25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  2023-04-05  2023-04-06  2023-04-07  2023-04-08  2023-04-09  2023-04-10  \\\n",
       "0   0           0           0           0           0           0           0   \n",
       "1   1           0           0           0           0           0           0   \n",
       "2   2           0           0           0           0           0           0   \n",
       "3   3           0           0           0           0           0           0   \n",
       "4   4           0           0           0           0           0           0   \n",
       "\n",
       "   2023-04-11  2023-04-12  2023-04-13  ...  2023-04-16  2023-04-17  \\\n",
       "0           0           0           0  ...           0           0   \n",
       "1           0           0           0  ...           0           0   \n",
       "2           0           0           0  ...           0           0   \n",
       "3           0           0           0  ...           0           0   \n",
       "4           0           0           0  ...           0           0   \n",
       "\n",
       "   2023-04-18  2023-04-19  2023-04-20  2023-04-21  2023-04-22  2023-04-23  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   2023-04-24  2023-04-25  \n",
       "0           0           0  \n",
       "1           0           0  \n",
       "2           0           0  \n",
       "3           0           0  \n",
       "4           0           0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>2023-04-05</th>\n",
       "      <th>2023-04-06</th>\n",
       "      <th>2023-04-07</th>\n",
       "      <th>2023-04-08</th>\n",
       "      <th>2023-04-09</th>\n",
       "      <th>2023-04-10</th>\n",
       "      <th>2023-04-11</th>\n",
       "      <th>2023-04-12</th>\n",
       "      <th>2023-04-13</th>\n",
       "      <th>...</th>\n",
       "      <th>2023-04-16</th>\n",
       "      <th>2023-04-17</th>\n",
       "      <th>2023-04-18</th>\n",
       "      <th>2023-04-19</th>\n",
       "      <th>2023-04-20</th>\n",
       "      <th>2023-04-21</th>\n",
       "      <th>2023-04-22</th>\n",
       "      <th>2023-04-23</th>\n",
       "      <th>2023-04-24</th>\n",
       "      <th>2023-04-25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  2023-04-05  2023-04-06  2023-04-07  2023-04-08  2023-04-09  2023-04-10  \\\n",
       "0   0           0           0           0           0           0           0   \n",
       "1   1           0           0           0           0           0           0   \n",
       "2   2           0           0           0           0           0           0   \n",
       "3   3           0           0           0           0           0           0   \n",
       "4   4           0           0           0           0           0           0   \n",
       "\n",
       "   2023-04-11  2023-04-12  2023-04-13  ...  2023-04-16  2023-04-17  \\\n",
       "0           0           0           0  ...           0           0   \n",
       "1           0           0           0  ...           0           0   \n",
       "2           0           0           0  ...           0           0   \n",
       "3           0           0           0  ...           0           0   \n",
       "4           2           0           0  ...           0           0   \n",
       "\n",
       "   2023-04-18  2023-04-19  2023-04-20  2023-04-21  2023-04-22  2023-04-23  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   2023-04-24  2023-04-25  \n",
       "0           0           0  \n",
       "1           0           0  \n",
       "2           0           0  \n",
       "3           0           0  \n",
       "4           0           0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.iloc[:,1:] = pred\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./SCINet_submit_5.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bsh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
